{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"reference:\n\nhttps://github.com/liuzechun/AdamBNN\n\nhttps://github.com/lopuhin/tpu-imagenet\n\n二值化网络：普通网络一般为实值化的，二值化在模型压缩等方面有着作用","metadata":{"id":"m7IlFVEpGOo7"}},{"cell_type":"code","source":"import os\nimport tensorflow\nimport numpy as np\nimport tensorflow.keras as keras\nimport tensorflow as tf","metadata":{"id":"oOSX1OGAKgye","execution":{"iopub.status.busy":"2021-08-23T02:07:08.559342Z","iopub.execute_input":"2021-08-23T02:07:08.559799Z","iopub.status.idle":"2021-08-23T02:07:15.040541Z","shell.execute_reply.started":"2021-08-23T02:07:08.559678Z","shell.execute_reply":"2021-08-23T02:07:15.039532Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"try: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:07:15.042358Z","iopub.execute_input":"2021-08-23T02:07:15.042771Z","iopub.status.idle":"2021-08-23T02:07:20.611821Z","shell.execute_reply.started":"2021-08-23T02:07:15.042712Z","shell.execute_reply":"2021-08-23T02:07:20.610542Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Number of accelerators:  8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# reactnet","metadata":{"id":"Eqt4qSAPNGln"}},{"cell_type":"code","source":"CONV_KER_INIT = 'glorot_uniform'\nCONV_BIAS_INIT = 'zeros'\nSTAGE_OUT_CHANNEL = [32]+[64]+[128]*2+[256]*2+[512]*6+[1024]*2\nWEIGHT_DECAY = 0.01","metadata":{"id":"GpSWsqzhHIdd","execution":{"iopub.status.busy":"2021-08-23T02:07:20.614204Z","iopub.execute_input":"2021-08-23T02:07:20.614616Z","iopub.status.idle":"2021-08-23T02:07:20.620142Z","shell.execute_reply.started":"2021-08-23T02:07:20.614572Z","shell.execute_reply":"2021-08-23T02:07:20.618754Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def conv3_3(out_planes, stride=1):\n    \"\"\"3*3 conv with padding\"\"\"\n    return keras.layers.Conv2D(\n        filters=out_planes,\n        kernel_size=3,\n        strides=stride,\n        use_bias=False,\n        kernel_initializer=CONV_KER_INIT,\n#         bias_initializer=CONV_BIAS_INIT,\n#         kernel_regularizer=keras.regularizers.l2(WEIGHT_DECAY),\n        padding = 'same',\n#         activation='relu',\n    )","metadata":{"id":"5so-iJLKK9oS","execution":{"iopub.status.busy":"2021-08-23T02:07:20.622699Z","iopub.execute_input":"2021-08-23T02:07:20.623144Z","iopub.status.idle":"2021-08-23T02:07:20.632946Z","shell.execute_reply.started":"2021-08-23T02:07:20.623099Z","shell.execute_reply":"2021-08-23T02:07:20.632127Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def conv1_1(out_planes, stride=1):\n    return keras.layers.Conv2D(\n        filters=out_planes,\n        kernel_size=1,\n        strides=stride,\n        use_bias=False,\n        kernel_initializer=CONV_KER_INIT,\n#         bias_initializer=CONV_KER_INIT,\n#         kernel_regularizer=keras.regularizers.l2(WEIGHT_DECAY),\n#         activation='relu',\n    )","metadata":{"id":"aUw8UWf4LAV4","execution":{"iopub.status.busy":"2021-08-23T02:07:20.634218Z","iopub.execute_input":"2021-08-23T02:07:20.634780Z","iopub.status.idle":"2021-08-23T02:07:20.646136Z","shell.execute_reply.started":"2021-08-23T02:07:20.634745Z","shell.execute_reply":"2021-08-23T02:07:20.645170Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class firstconv3_3(keras.layers.Layer):\n    def __init__(self, oup, stride):\n        super(firstconv3_3, self).__init__()\n        self.conv1 = keras.layers.Conv2D(\n            filters=oup,\n            kernel_size=3,\n            strides=stride,\n            use_bias=False,\n            kernel_initializer=CONV_KER_INIT,\n#             bias_initializer=CONV_BIAS_INIT,\n#             kernel_regularizer=keras.regularizers.l2(WEIGHT_DECAY),\n            padding = 'same',\n#             activation='relu',\n        )\n        self.bn = keras.layers.BatchNormalization()\n    \n    def call(self, x):\n        out = self.conv1(x)\n        out = self.bn(out)\n        return out","metadata":{"id":"XdfoBRaOIavm","execution":{"iopub.status.busy":"2021-08-23T02:07:20.647430Z","iopub.execute_input":"2021-08-23T02:07:20.647864Z","iopub.status.idle":"2021-08-23T02:07:20.660017Z","shell.execute_reply.started":"2021-08-23T02:07:20.647833Z","shell.execute_reply":"2021-08-23T02:07:20.659034Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class BinaryActivation(keras.layers.Layer):\n    def __init__(self, ):\n        super(BinaryActivation, self).__init__()\n\n    def call(self, x):\n        out_forward = tf.math.sign(x)\n        mask1 = x < -1\n        mask2 = x < 0\n        mask3 = x < 1\n        out1 = (-1)*tf.cast(mask1, tf.float32) + (x*x+2*x)*(1-tf.cast(mask1, tf.float32))\n        out2 = out1*tf.cast(mask2, tf.float32) + (-x*x+2*x)*(1-tf.cast(mask2, tf.float32))\n        out3 = out2*tf.cast(mask3, tf.float32) + 1*(1-tf.cast(mask3, tf.float32))\n        out = out_forward-out3+out3\n        return out","metadata":{"id":"vq0Zp-SRtzip","execution":{"iopub.status.busy":"2021-08-23T02:07:20.661123Z","iopub.execute_input":"2021-08-23T02:07:20.661418Z","iopub.status.idle":"2021-08-23T02:07:20.678370Z","shell.execute_reply.started":"2021-08-23T02:07:20.661391Z","shell.execute_reply":"2021-08-23T02:07:20.677327Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class LearnableBias(keras.layers.Layer):\n    def __init__(self, out_chn, size=None):\n        super(LearnableBias, self).__init__()\n        self.size = size\n        self.out_chn = out_chn\n        self.b = self.add_weight(\n            shape=(1, 1, self.out_chn),\n            initializer='zeros',\n            trainable=True,\n        )\n    \n    def call(self, x):\n        out = tf.add(x, self.b)\n        return out","metadata":{"id":"oFFqlQobvC38","execution":{"iopub.status.busy":"2021-08-23T02:07:20.679434Z","iopub.execute_input":"2021-08-23T02:07:20.679763Z","iopub.status.idle":"2021-08-23T02:07:20.693330Z","shell.execute_reply.started":"2021-08-23T02:07:20.679701Z","shell.execute_reply":"2021-08-23T02:07:20.692090Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"'''test LearnableBias'''\n# import torch\n# import torch.nn as nn\n# import torch.utils.model_zoo as model_zoo\n# import torch.nn.functional as F\n# import numpy as np\n# class ptLearnableBias(nn.Module):\n#     def __init__(self, out_chn):\n#         super(ptLearnableBias, self).__init__()\n#         self.bias = nn.Parameter(torch.zeros(1,out_chn,1,1), requires_grad=True)\n\n#     def forward(self, x):\n#         out = x + self.bias.expand_as(x)\n#         return out\n# img = np.random.normal(size=(2, 3, 24, 24))\n# label = np.random.normal(size=(2, 3, 24, 24))\n\n# pt_img = torch.from_numpy(img)\n# pt_label = torch.from_numpy(label)\n# pt_layer = ptLearnableBias(3)\n# pt_out = pt_layer(pt_img)\n# pt_loss = nn.MSELoss()\n# pt_optimizer = torch.optim.Adam(params=pt_layer.parameters(), lr=0.9, betas=(0.9,0.999), eps=1e-08)\n\n# pt_output = pt_loss(pt_out, pt_label)\n# print(pt_output)\n# pt_optimizer.zero_grad()\n# pt_output.backward()\n# pt_optimizer.step()\n# print(pt_layer.bias)\n# print('------------\\n')\n\n\n# tf_img = tf.convert_to_tensor(img)\n# tf_img = tf.transpose(tf_img, perm=[0, 2, 3, 1])\n# tf_label = tf.convert_to_tensor(label)\n# tf_label = tf.transpose(tf_label, perm=[0, 2, 3, 1])\n# tf_layer = LearnableBias(3)\n# tf_loss = tf.keras.losses.MeanSquaredError()\n# tf_optimizer = tf.keras.optimizers.Adam(learning_rate=0.9, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n# with tf.GradientTape() as tape:\n#     tf_out = tf_layer(tf_img)\n#     tf_output = tf_loss(tf_label, tf_out)\n# grads = tape.gradient(tf_output, tf_layer.trainable_weights)\n# tf_optimizer.apply_gradients(list(zip(grads, tf_layer.trainable_weights)))\n# print(tf_output)\n# print(tf_layer.trainable_weights)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:07:20.696047Z","iopub.execute_input":"2021-08-23T02:07:20.696375Z","iopub.status.idle":"2021-08-23T02:07:20.709471Z","shell.execute_reply.started":"2021-08-23T02:07:20.696338Z","shell.execute_reply":"2021-08-23T02:07:20.708659Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'test LearnableBias'"},"metadata":{}}]},{"cell_type":"code","source":"class BasicBlock(keras.layers.Layer):\n    def __init__(self, inplanes, planes, size=None, stride=1):\n        super(BasicBlock, self).__init__()\n        self.move11 = LearnableBias(inplanes, size)\n        self.binary_3_3 = conv3_3(inplanes, stride=stride)\n        self.bn1 = keras.layers.BatchNormalization()\n\n        self.move12 = LearnableBias(inplanes, size)\n        self.prelu1 = keras.layers.PReLU()\n        self.move13 = LearnableBias(inplanes, size)\n\n        self.move21 = LearnableBias(inplanes, size)\n\n        if inplanes == planes:\n            self.binary_pw = conv1_1(planes, stride=stride)\n            self.bn2 = keras.layers.BatchNormalization()\n        else:\n            self.binary_pw_down1 = conv1_1(inplanes)\n            self.binary_pw_down2 = conv1_1(inplanes)\n            self.bn2_1 = keras.layers.BatchNormalization()\n            self.bn2_2 = keras.layers.BatchNormalization()\n        \n        self.move22 = LearnableBias(planes, size)\n        self.prelu2 = keras.layers.PReLU()\n        self.move23 = LearnableBias(planes, size)\n\n        self.binary_activation = BinaryActivation()\n        self.stride = stride\n        self.inplanes = inplanes\n        self.planes = planes\n\n        if self.inplanes != self.planes:\n            self.pooling = keras.layers.AveragePooling2D(pool_size=(2, 2))\n\n    def call(self, x):\n        out1 = self.move11(x)\n\n        out1 = self.binary_activation(out1)\n        out1 = self.binary_3_3(out1)\n        out1 = self.bn1(out1)\n\n        if self.stride == 2:\n            x = self.pooling(x)\n        \n        out1 = x+out1\n        out1 = self.move12(out1)\n        out1 = self.prelu1(out1)\n        out1 = self.move13(out1)\n\n        out2 = self.move21(out1)\n        out2 = self.binary_activation(out2)\n\n        if self.inplanes == self.planes:\n            out2 = self.binary_pw(out2)\n            out2 = self.bn2(out2)\n            out2 += out1\n        else:\n            assert self.planes == self.inplanes * 2\n            out2_1 = self.binary_pw_down1(out2)\n            out2_2 = self.binary_pw_down2(out2)\n            out2_1 = self.bn2_1(out2_1)\n            out2_2 = self.bn2_2(out2_2)\n            out2_1 += out1\n            out2_2 += out1\n            out2 = tf.concat([out2_1, out2_2], axis=-1)\n        \n        out2 = self.move22(out2)\n        out2 = self.prelu2(out2)\n        out2 = self.move23(out2)\n        return out2","metadata":{"id":"LCG4DfHU2_WS","execution":{"iopub.status.busy":"2021-08-23T02:07:20.710911Z","iopub.execute_input":"2021-08-23T02:07:20.711323Z","iopub.status.idle":"2021-08-23T02:07:20.731360Z","shell.execute_reply.started":"2021-08-23T02:07:20.711292Z","shell.execute_reply":"2021-08-23T02:07:20.730195Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class reactnet(keras.Model):\n    def __init__(self, num_classes, stage_out_channel,):\n        super(reactnet, self).__init__()\n        self.feature = keras.Sequential()\n        \n        for i in range(len(stage_out_channel)):\n            if i==0:\n                self.feature.add(firstconv3_3(stage_out_channel[i], 2))\n            elif stage_out_channel[i-1] != stage_out_channel[i] and stage_out_channel[i] != 64:\n                self.feature.add(\n                    BasicBlock(stage_out_channel[i-1], stage_out_channel[i], stride=2)\n                )\n            else:\n                self.feature.add(\n                    BasicBlock(stage_out_channel[i-1], stage_out_channel[i], stride=1)\n                )\n        self.pool1 = keras.layers.GlobalAveragePooling2D()\n        self.fc = keras.layers.Dense(num_classes)\n    \n    def call(self, inputs):\n        x = self.feature(inputs)\n        x = self.pool1(x)\n        x = self.fc(x)\n        return x","metadata":{"id":"RZAEoATz2_TS","execution":{"iopub.status.busy":"2021-08-23T02:07:20.733086Z","iopub.execute_input":"2021-08-23T02:07:20.733885Z","iopub.status.idle":"2021-08-23T02:07:20.753766Z","shell.execute_reply.started":"2021-08-23T02:07:20.733840Z","shell.execute_reply":"2021-08-23T02:07:20.752584Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def model(image_size, num_classes, stage_out_channel):\n    inputs = keras.Input((image_size, image_size, 3))\n    outputs = reactnet(num_classes, stage_out_channel)(inputs)\n    model = keras.Model(inputs, outputs)\n    return model","metadata":{"id":"ecVTEGrvq8HT","execution":{"iopub.status.busy":"2021-08-23T02:07:20.755047Z","iopub.execute_input":"2021-08-23T02:07:20.755495Z","iopub.status.idle":"2021-08-23T02:07:20.772226Z","shell.execute_reply.started":"2021-08-23T02:07:20.755456Z","shell.execute_reply":"2021-08-23T02:07:20.770917Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"react = model(224, 1000, STAGE_OUT_CHANNEL)\nreact.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:07:20.773330Z","iopub.execute_input":"2021-08-23T02:07:20.773624Z","iopub.status.idle":"2021-08-23T02:07:24.503887Z","shell.execute_reply.started":"2021-08-23T02:07:20.773589Z","shell.execute_reply":"2021-08-23T02:07:24.502825Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nreactnet (reactnet)          (None, 1000)              33995848  \n=================================================================\nTotal params: 33,995,848\nTrainable params: 33,973,960\nNon-trainable params: 21,888\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# for layer in react.layers[-1].feature.layers:\n#     if 'basic_block' in layer.name:\n#         for i in range(len(layer.trainable_weights)):\n#             print(layer.trainable_weights[i].name)\n#             print(layer.trainable_weights[i].shape)\n#         print('------')\n#         print(len(layer.trainable_weights))\n#         break","metadata":{"id":"AF7afhejvFV7","outputId":"dc3d56fd-a694-4c61-8dea-f5443ba0d61f","execution":{"iopub.status.busy":"2021-08-23T02:07:24.505569Z","iopub.execute_input":"2021-08-23T02:07:24.506010Z","iopub.status.idle":"2021-08-23T02:07:24.510674Z","shell.execute_reply.started":"2021-08-23T02:07:24.505965Z","shell.execute_reply":"2021-08-23T02:07:24.509309Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{"id":"gWb2o4YIBoCQ"}},{"cell_type":"code","source":"with strategy.scope():\n    class myLoss(keras.losses.Loss):\n        def __init__(self):\n            super(myLoss, self).__init__(reduction=tf.keras.losses.Reduction.NONE)\n\n        def call(self, y_true, y_pred):\n            model_output_log_prob = tf.math.log(keras.activations.softmax(y_pred))\n            real_output_soft = keras.activations.softmax(y_true)\n\n            real_output_soft = tf.expand_dims(real_output_soft, axis=1)\n            model_output_log_prob = tf.expand_dims(model_output_log_prob, axis=-1)\n            cross_entropy_loss = -tf.einsum('bij, bji->bi', real_output_soft, model_output_log_prob)\n\n            return cross_entropy_loss","metadata":{"id":"oGgXh-G7Bqzh","execution":{"iopub.status.busy":"2021-08-23T02:07:24.512216Z","iopub.execute_input":"2021-08-23T02:07:24.512700Z","iopub.status.idle":"2021-08-23T02:07:24.525285Z","shell.execute_reply.started":"2021-08-23T02:07:24.512645Z","shell.execute_reply":"2021-08-23T02:07:24.524169Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"#  Learning rate schedule","metadata":{}},{"cell_type":"code","source":"class MyLRSchedule(keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, initial_learning_rate, epochs, step_epoch):\n        self.initial_learning_rate = initial_learning_rate\n        self.all_step = epochs * step_epoch\n        \n    def __call__(self, step):\n        return self.initial_learning_rate*(1.0 - (step/(self.all_step)))","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:07:24.526496Z","iopub.execute_input":"2021-08-23T02:07:24.526827Z","iopub.status.idle":"2021-08-23T02:07:24.542734Z","shell.execute_reply.started":"2021-08-23T02:07:24.526799Z","shell.execute_reply":"2021-08-23T02:07:24.541533Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"8aqEEx5mqVDe"}},{"cell_type":"code","source":"def read_tfrecord(example):\n    features = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'class': tf.io.FixedLenFeature([], tf.int64),\n        'filename': tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, features)\n    image = tf.image.decode_jpeg(example['image'])\n    class_num = example['class']\n    filename = example['filename']\n    return image, class_num, filename","metadata":{"id":"48XxwpPoKE5K","execution":{"iopub.status.busy":"2021-08-23T02:07:24.544244Z","iopub.execute_input":"2021-08-23T02:07:24.544559Z","iopub.status.idle":"2021-08-23T02:07:24.554430Z","shell.execute_reply.started":"2021-08-23T02:07:24.544532Z","shell.execute_reply":"2021-08-23T02:07:24.553451Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def image_hw(image):\n    shape = tf.shape(image)\n    return shape[0], shape[1]\n\ndef resize_and_crop_image(image, target_size):\n    h, w = image_hw(image)\n    th, tw = target_size\n    image = tf.cond(\n        (w*th)/(h*tw) <1,\n        lambda: tf.image.resize(image, [h * tw/w, w* tw/w]),\n        lambda: tf.image.resize(image, [h * th/h, w*th/h])\n    )\n    nh, nw = image_hw(image)\n    image = tf.image.crop_to_bounding_box(image, (nh-th)//2, (nw-tw)//2, th, tw)\n    image = tf.reshape(image, [*target_size, 3])\n    return image\n\ndef normalize(image, dtype):\n    image = tf.cast(image, dtype) / 255.0\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:07:24.555822Z","iopub.execute_input":"2021-08-23T02:07:24.556093Z","iopub.status.idle":"2021-08-23T02:07:24.566460Z","shell.execute_reply.started":"2021-08-23T02:07:24.556068Z","shell.execute_reply":"2021-08-23T02:07:24.565460Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def dataset(tfrec_roots, image_size, is_train, dtype=tf.float32, batch_size=None, cache=False, drop_filename=True):\n    AUTO = tf.data.experimental.AUTOTUNE\n    pattern = '/train-*.tfrec' if is_train else '/val.tfrec'\n    tfrec_paths = []\n    for tfrec_root in tfrec_roots:\n        tfrec_paths.extend(tf.io.gfile.glob(tfrec_root.rstrip('/')+pattern))\n#     print('tfrec paths', tfrec_paths)\n    dataset = tf.data.TFRecordDataset(tfrec_paths, num_parallel_reads=AUTO)\n    options_no_order = tf.data.Options()\n    options_no_order.experimental_deterministic = False\n    dataset = dataset.with_options(options_no_order)\n\n    def process(filename):\n        image, label, filename = read_tfrecord(filename)\n        image = resize_and_crop_image(image, target_size=image_size)\n        image = tf.image.random_flip_left_right(image)\n        image = normalize(image, dtype=dtype)\n        result = (image, label)\n        if not drop_filename:\n            result += (filenmae,)\n        return result\n        \n    dataset = dataset.map(process, num_parallel_calls=AUTO)\n    if cache:\n        dataset = dataset.cache()\n    if is_train:\n        dataset = dataset.shuffle(4096)\n    if batch_size is not None:\n        dataset = dataset.batch(batch_size)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(AUTO)\n    return dataset","metadata":{"id":"ROFfrOieLgBd","execution":{"iopub.status.busy":"2021-08-23T02:07:24.567640Z","iopub.execute_input":"2021-08-23T02:07:24.567927Z","iopub.status.idle":"2021-08-23T02:07:24.581797Z","shell.execute_reply.started":"2021-08-23T02:07:24.567902Z","shell.execute_reply":"2021-08-23T02:07:24.580810Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# train","metadata":{"id":"JxwAVgY36gGo"}},{"cell_type":"code","source":"from pathlib import Path\nfrom kaggle_datasets import KaggleDatasets\ngcs_path = [KaggleDatasets().get_gcs_path(p.name) for p in Path('/kaggle/input/').iterdir()]\nIMAGE_SIZE = 224\nN_CLASSES = 1000\nXLA = 0\nMIXED = 1\nBATCH_SIZE = 256\nEPOCHS = 256\nLEARNING_RATE = 1.25e-3\nMOMENTUM = 0.9\nLABEL_SMOOTH =0.1\nTEACHER = 'ResNet50'","metadata":{"id":"2z-nkm6zm-5A","execution":{"iopub.status.busy":"2021-08-23T02:07:24.583191Z","iopub.execute_input":"2021-08-23T02:07:24.583470Z","iopub.status.idle":"2021-08-23T02:07:25.614307Z","shell.execute_reply.started":"2021-08-23T02:07:24.583443Z","shell.execute_reply":"2021-08-23T02:07:25.613199Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"if MIXED:\n    dtype = tf.bfloat16 if tpu else tf.float16\nNUM_TRAIN_IMAGES = 1281167\nNUM_VAL_IMAGES = 50000\nSTEP_PER_EPOCH = NUM_TRAIN_IMAGES // BATCH_SIZE\nVAL_PER_EPOCH = NUM_VAL_IMAGES // BATCH_SIZE\nPER_REPICE_BATCH_SIZE = BATCH_SIZE // strategy.num_replicas_in_sync\nSAVE_PATH = './model.h5'\n\ntrain_dataset = strategy.experimental_distribute_datasets_from_function(\n    lambda _:dataset(\n            gcs_path,\n            is_train=True, \n            image_size=(IMAGE_SIZE, IMAGE_SIZE), \n            cache=False, \n            batch_size=PER_REPICE_BATCH_SIZE,\n            drop_filename=True,\n            dtype=dtype,\n            ))\nval_dataset = strategy.experimental_distribute_datasets_from_function(lambda _:dataset(\n            gcs_path,\n            is_train=False, \n            image_size=(IMAGE_SIZE, IMAGE_SIZE), \n            cache=True, \n            batch_size=PER_REPICE_BATCH_SIZE,\n            drop_filename=True,\n            dtype=dtype,\n            ))\ntrain_iterator = iter(train_dataset)\nval_iterator = iter(val_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:07:25.615560Z","iopub.execute_input":"2021-08-23T02:07:25.615873Z","iopub.status.idle":"2021-08-23T02:07:27.560988Z","shell.execute_reply.started":"2021-08-23T02:07:25.615845Z","shell.execute_reply":"2021-08-23T02:07:27.559861Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\"\"\"load model\"\"\"\nwith strategy.scope():\n    model_teacher = keras.applications.__dict__[TEACHER](weights='imagenet', include_top=True)\n    model_teacher.trainable = False\n\n    model_student = model(224, 1000, STAGE_OUT_CHANNEL)\n\n    lr_schedule = MyLRSchedule(LEARNING_RATE, EPOCHS, STEP_PER_EPOCH)\n    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999)\n    criterion = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    criterion_smooth = keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0)\n    criterion_kd = myLoss()\n    training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('training_accuracy', dtype=tf.float32)\n    training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n    val_accuracy =tf.keras.metrics.SparseCategoricalAccuracy('val_accuracy', dtype=tf.float32)\n\n\n@tf.function\ndef train_step(iterator):\n    def train_fn(inputs):\n        x, y = inputs\n        with tf.GradientTape() as tape:\n            logits_student = model_student(x, training=True)\n            logits_teacher = model_teacher(x, training=False)\n            loss = criterion_kd(logits_teacher, logits_student)\n            loss = tf.nn.compute_average_loss(loss, global_batch_size=BATCH_SIZE)\n            \n        grads = tape.gradient(loss, model_student.trainable_weights)\n        optimizer.apply_gradients(list(zip(grads, model_student.trainable_weights)))\n        training_accuracy.update_state(y, logits_student)\n        training_loss.update_state(loss)\n    \n    strategy.run(train_fn, args=(next(iterator),))\n    \n@tf.function\ndef test_step(iterator):\n    def test_fn(inputs):\n        x, y = inputs\n        val_logits = model_student(x, training=False)\n        val_accuracy.update_state(y, val_logits)\n    strategy.run(test_fn, args=(next(iterator),))","metadata":{"id":"_WBi0QOF3s8y","outputId":"c43a8c11-6b31-4e7a-f064-f33c51d017b5","execution":{"iopub.status.busy":"2021-08-23T02:07:27.562625Z","iopub.execute_input":"2021-08-23T02:07:27.563066Z","iopub.status.idle":"2021-08-23T02:07:46.929788Z","shell.execute_reply.started":"2021-08-23T02:07:27.563011Z","shell.execute_reply":"2021-08-23T02:07:46.928851Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n102973440/102967424 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    print('\\nstart of epoch %d'%(epoch,))\n    for step in range(STEP_PER_EPOCH):\n        train_step(train_iterator)    \n    train_acc = training_accuracy.result()\n    print('training acc over epoch: %.4f, %4f'%(float(train_acc), float(training_loss.result())))\n    training_accuracy.reset_states()\n    training_loss.reset_states()\n\n    for step in range(VAL_PER_EPOCH):\n        test_step(val_iterator)\n    val_acc = val_accuracy.result()\n    print('validation acc over epoch: %.4f'%(float(val_acc),))\n    val_accuracy.reset_states()","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:07:46.931796Z","iopub.execute_input":"2021-08-23T02:07:46.932211Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\nstart of epoch 0\ntraining acc over epoch: 0.0010, 0.864433\nvalidation acc over epoch: 0.0010\n\nstart of epoch 1\ntraining acc over epoch: 0.0010, 0.863488\nvalidation acc over epoch: 0.0010\n\nstart of epoch 2\ntraining acc over epoch: 0.0010, 0.863487\nvalidation acc over epoch: 0.0010\n\nstart of epoch 3\n","output_type":"stream"}]},{"cell_type":"code","source":"model_student.save_weights(SAVE_PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}