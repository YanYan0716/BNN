{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"reference:\n\nhttps://github.com/liuzechun/AdamBNN\n\nhttps://github.com/lopuhin/tpu-imagenet\n\n二值化网络：普通网络一般为实值化的，二值化在模型压缩等方面有着作用","metadata":{"id":"m7IlFVEpGOo7"}},{"cell_type":"code","source":"import os\nimport tensorflow\nimport numpy as np\nimport tensorflow.keras as keras\nimport tensorflow as tf\nimport tensorflow_addons as tfa","metadata":{"id":"oOSX1OGAKgye","execution":{"iopub.status.busy":"2021-08-25T02:18:12.741274Z","iopub.execute_input":"2021-08-25T02:18:12.741907Z","iopub.status.idle":"2021-08-25T02:18:18.585901Z","shell.execute_reply.started":"2021-08-25T02:18:12.741821Z","shell.execute_reply":"2021-08-25T02:18:18.584855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T02:18:18.589369Z","iopub.execute_input":"2021-08-25T02:18:18.58971Z","iopub.status.idle":"2021-08-25T02:18:24.049432Z","shell.execute_reply.started":"2021-08-25T02:18:18.589682Z","shell.execute_reply":"2021-08-25T02:18:24.048377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# reactnet","metadata":{"id":"Eqt4qSAPNGln"}},{"cell_type":"code","source":"CONV_KER_INIT = 'glorot_uniform'\nCONV_BIAS_INIT = 'zeros'\nSTAGE_OUT_CHANNEL = [32]+[64]+[128]*2+[256]*2+[512]*6+[1024]*2\nWEIGHT_DECAY = 0.01","metadata":{"id":"GpSWsqzhHIdd","execution":{"iopub.status.busy":"2021-08-25T02:18:24.051001Z","iopub.execute_input":"2021-08-25T02:18:24.05128Z","iopub.status.idle":"2021-08-25T02:18:24.055868Z","shell.execute_reply.started":"2021-08-25T02:18:24.051253Z","shell.execute_reply":"2021-08-25T02:18:24.054862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv3_3(out_planes, stride=1):\n    \"\"\"3*3 conv with padding\"\"\"\n    return keras.layers.Conv2D(\n        filters=out_planes,\n        kernel_size=3,\n        strides=stride,\n        use_bias=False,\n        kernel_initializer=CONV_KER_INIT,\n#         bias_initializer=CONV_BIAS_INIT,\n#         kernel_regularizer=keras.regularizers.l2(WEIGHT_DECAY),\n        padding = 'same',\n#         activation='relu',\n    )","metadata":{"id":"5so-iJLKK9oS","execution":{"iopub.status.busy":"2021-08-25T02:18:24.057271Z","iopub.execute_input":"2021-08-25T02:18:24.057642Z","iopub.status.idle":"2021-08-25T02:18:24.068034Z","shell.execute_reply.started":"2021-08-25T02:18:24.057615Z","shell.execute_reply":"2021-08-25T02:18:24.067055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv1_1(out_planes, stride=1):\n    return keras.layers.Conv2D(\n        filters=out_planes,\n        kernel_size=1,\n        strides=stride,\n        use_bias=False,\n        kernel_initializer=CONV_KER_INIT,\n#         bias_initializer=CONV_KER_INIT,\n#         kernel_regularizer=keras.regularizers.l2(WEIGHT_DECAY),\n#         activation='relu',\n    )","metadata":{"id":"aUw8UWf4LAV4","execution":{"iopub.status.busy":"2021-08-25T02:18:24.069522Z","iopub.execute_input":"2021-08-25T02:18:24.069912Z","iopub.status.idle":"2021-08-25T02:18:24.079754Z","shell.execute_reply.started":"2021-08-25T02:18:24.069871Z","shell.execute_reply":"2021-08-25T02:18:24.078977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class firstconv3_3(keras.layers.Layer):\n    def __init__(self, oup, stride):\n        super(firstconv3_3, self).__init__()\n        self.conv1 = keras.layers.Conv2D(\n            filters=oup,\n            kernel_size=3,\n            strides=stride,\n            use_bias=False,\n            kernel_initializer=CONV_KER_INIT,\n#             bias_initializer=CONV_BIAS_INIT,\n#             kernel_regularizer=keras.regularizers.l2(WEIGHT_DECAY),\n            padding = 'same',\n#             activation='relu',\n        )\n        self.bn = keras.layers.BatchNormalization()\n    \n    def call(self, x):\n        out = self.conv1(x)\n        out = self.bn(out)\n        return out","metadata":{"id":"XdfoBRaOIavm","execution":{"iopub.status.busy":"2021-08-25T02:18:24.080851Z","iopub.execute_input":"2021-08-25T02:18:24.08135Z","iopub.status.idle":"2021-08-25T02:18:24.091139Z","shell.execute_reply.started":"2021-08-25T02:18:24.08131Z","shell.execute_reply":"2021-08-25T02:18:24.090443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BinaryActivation(keras.layers.Layer):\n    def __init__(self, ):\n        super(BinaryActivation, self).__init__()\n\n    def call(self, x):\n        out_forward = tf.math.sign(x)\n        mask1 = x < -1\n        mask2 = x < 0\n        mask3 = x < 1\n        out1 = (-1)*tf.cast(mask1, tf.float32) + (x*x+2*x)*(1-tf.cast(mask1, tf.float32))\n        out2 = out1*tf.cast(mask2, tf.float32) + (-x*x+2*x)*(1-tf.cast(mask2, tf.float32))\n        out3 = out2*tf.cast(mask3, tf.float32) + 1*(1-tf.cast(mask3, tf.float32))\n        out = out_forward-out3+out3\n        return out","metadata":{"id":"vq0Zp-SRtzip","execution":{"iopub.status.busy":"2021-08-25T02:18:24.092278Z","iopub.execute_input":"2021-08-25T02:18:24.09262Z","iopub.status.idle":"2021-08-25T02:18:24.109791Z","shell.execute_reply.started":"2021-08-25T02:18:24.092591Z","shell.execute_reply":"2021-08-25T02:18:24.108726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"test binaryactivation\"\"\"\n# import torch\n# class pt_BinaryActivation(torch.nn.Module):\n#     def __init__(self):\n#         super(pt_BinaryActivation, self).__init__()\n\n#     def forward(self, x):\n#         out_forward = torch.sign(x)\n#         mask1 = x < -1\n#         mask2 = x < 0\n#         mask3 = x < 1\n#         out1 = (-1) * mask1.type(torch.float32) + (x*x + 2*x) * (1-mask1.type(torch.float32))\n#         out2 = out1 * mask2.type(torch.float32) + (-x*x + 2*x) * (1-mask2.type(torch.float32))\n#         out3 = out2 * mask3.type(torch.float32) + 1 * (1- mask3.type(torch.float32))\n#         out = out_forward.detach() - out3.detach() + out3\n\n#         return out\n\n# img = np.random.normal(size=(2, 3, 8, 8))\n\n# pt_img = torch.from_numpy(img)\n# pt_layer = pt_BinaryActivation()\n# pt_out = pt_layer(pt_img)\n\n# print(pt_out[0][0])\n# print('------------')\n\n\n# tf_img =tf.convert_to_tensor(img)\n# tf_img = tf.transpose(tf_img, perm=[0, 2, 3, 1])\n# tf_layer = BinaryActivation()\n# tf_out = tf_layer(tf_img)\n# print(tf_out[0,:,:,0])","metadata":{"execution":{"iopub.status.busy":"2021-08-25T02:18:24.113177Z","iopub.execute_input":"2021-08-25T02:18:24.113829Z","iopub.status.idle":"2021-08-25T02:18:24.125826Z","shell.execute_reply.started":"2021-08-25T02:18:24.113782Z","shell.execute_reply":"2021-08-25T02:18:24.125065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LearnableBias(keras.layers.Layer):\n    def __init__(self, out_chn, size=None):\n        super(LearnableBias, self).__init__()\n        self.size = size\n        self.out_chn = out_chn\n        self.b = self.add_weight(\n            shape=(1, 1, self.out_chn),\n            initializer='zeros',\n            trainable=True,\n        )\n    \n    def call(self, x):\n        out = tf.add(x, self.b)\n        return out","metadata":{"id":"oFFqlQobvC38","execution":{"iopub.status.busy":"2021-08-25T02:18:24.127436Z","iopub.execute_input":"2021-08-25T02:18:24.12794Z","iopub.status.idle":"2021-08-25T02:18:24.14114Z","shell.execute_reply.started":"2021-08-25T02:18:24.127909Z","shell.execute_reply":"2021-08-25T02:18:24.1404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''test LearnableBias'''\n# import torch\n# import torch.nn as nn\n# import torch.utils.model_zoo as model_zoo\n# import torch.nn.functional as F\n# import numpy as np\n# class ptLearnableBias(nn.Module):\n#     def __init__(self, out_chn):\n#         super(ptLearnableBias, self).__init__()\n#         self.bias = nn.Parameter(torch.zeros(1,out_chn,1,1), requires_grad=True)\n\n#     def forward(self, x):\n#         out = x + self.bias.expand_as(x)\n#         return out\n# img = np.random.normal(size=(2, 3, 24, 24))\n# label = np.random.normal(size=(2, 3, 24, 24))\n\n# pt_img = torch.from_numpy(img)\n# pt_label = torch.from_numpy(label)\n# pt_layer = ptLearnableBias(3)\n# pt_out = pt_layer(pt_img)\n# pt_loss = nn.MSELoss()\n# pt_optimizer = torch.optim.Adam(params=pt_layer.parameters(), lr=0.9, betas=(0.9,0.999), eps=1e-08)\n\n# pt_output = pt_loss(pt_out, pt_label)\n# print(pt_output)\n# pt_optimizer.zero_grad()\n# pt_output.backward()\n# pt_optimizer.step()\n# print(pt_layer.bias)\n# print('------------\\n')\n\n\n# tf_img = tf.convert_to_tensor(img)\n# tf_img = tf.transpose(tf_img, perm=[0, 2, 3, 1])\n# tf_label = tf.convert_to_tensor(label)\n# tf_label = tf.transpose(tf_label, perm=[0, 2, 3, 1])\n# tf_layer = LearnableBias(3)\n# tf_loss = tf.keras.losses.MeanSquaredError()\n# tf_optimizer = tf.keras.optimizers.Adam(learning_rate=0.9, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n# with tf.GradientTape() as tape:\n#     tf_out = tf_layer(tf_img)\n#     tf_output = tf_loss(tf_label, tf_out)\n# grads = tape.gradient(tf_output, tf_layer.trainable_weights)\n# tf_optimizer.apply_gradients(list(zip(grads, tf_layer.trainable_weights)))\n# print(tf_output)\n# print(tf_layer.trainable_weights)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T02:18:24.142195Z","iopub.execute_input":"2021-08-25T02:18:24.142602Z","iopub.status.idle":"2021-08-25T02:18:24.154437Z","shell.execute_reply.started":"2021-08-25T02:18:24.142573Z","shell.execute_reply":"2021-08-25T02:18:24.153734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(keras.layers.Layer):\n    def __init__(self, inplanes, planes, size=None, stride=1):\n        super(BasicBlock, self).__init__()\n        self.move11 = LearnableBias(inplanes, size)\n        self.binary_3_3 = conv3_3(inplanes, stride=stride)\n        self.bn1 = keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-05)\n\n        self.move12 = LearnableBias(inplanes, size)\n        self.prelu1 = keras.layers.PReLU()\n        self.move13 = LearnableBias(inplanes, size)\n\n        self.move21 = LearnableBias(inplanes, size)\n\n        if inplanes == planes:\n            self.binary_pw = conv1_1(planes, stride=stride)\n            self.bn2 = keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-05)\n        else:\n            self.binary_pw_down1 = conv1_1(inplanes)\n            self.binary_pw_down2 = conv1_1(inplanes)\n            self.bn2_1 = keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-05)\n            self.bn2_2 = keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-05)\n        \n        self.move22 = LearnableBias(planes, size)\n        self.prelu2 = keras.layers.PReLU()\n        self.move23 = LearnableBias(planes, size)\n\n        self.binary_activation = BinaryActivation()\n        self.stride = stride\n        self.inplanes = inplanes\n        self.planes = planes\n\n        if self.inplanes != self.planes:\n            self.pooling = keras.layers.AveragePooling2D(pool_size=(2, 2))\n\n    def call(self, x):\n        out1 = self.move11(x)\n\n        out1 = self.binary_activation(out1)\n        out1 = self.binary_3_3(out1)\n        out1 = self.bn1(out1)\n\n        if self.stride == 2:\n            x = self.pooling(x)\n        \n        out1 = x+out1\n        out1 = self.move12(out1)\n        out1 = self.prelu1(out1)\n        out1 = self.move13(out1)\n\n        out2 = self.move21(out1)\n        out2 = self.binary_activation(out2)\n\n        if self.inplanes == self.planes:\n            out2 = self.binary_pw(out2)\n            out2 = self.bn2(out2)\n            out2 += out1\n        else:\n            assert self.planes == self.inplanes * 2\n            out2_1 = self.binary_pw_down1(out2)\n            out2_2 = self.binary_pw_down2(out2)\n            out2_1 = self.bn2_1(out2_1)\n            out2_2 = self.bn2_2(out2_2)\n            out2_1 += out1\n            out2_2 += out1\n            out2 = tf.concat([out2_1, out2_2], axis=-1)\n        \n        out2 = self.move22(out2)\n        out2 = self.prelu2(out2)\n        out2 = self.move23(out2)\n        return out2","metadata":{"id":"LCG4DfHU2_WS","execution":{"iopub.status.busy":"2021-08-25T02:18:24.156064Z","iopub.execute_input":"2021-08-25T02:18:24.156514Z","iopub.status.idle":"2021-08-25T02:18:24.173018Z","shell.execute_reply.started":"2021-08-25T02:18:24.156484Z","shell.execute_reply":"2021-08-25T02:18:24.172305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class reactnet(keras.Model):\n    def __init__(self, num_classes, stage_out_channel,):\n        super(reactnet, self).__init__()\n        self.feature = keras.Sequential()\n        \n        for i in range(len(stage_out_channel)):\n            if i==0:\n                self.feature.add(firstconv3_3(stage_out_channel[i], 2))\n            elif stage_out_channel[i-1] != stage_out_channel[i] and stage_out_channel[i] != 64:\n                self.feature.add(\n                    BasicBlock(stage_out_channel[i-1], stage_out_channel[i], stride=2)\n                )\n            else:\n                self.feature.add(\n                    BasicBlock(stage_out_channel[i-1], stage_out_channel[i], stride=1)\n                )\n        self.pool1 = keras.layers.GlobalAveragePooling2D()\n        self.fc = keras.layers.Dense(num_classes)\n    \n    def call(self, inputs):\n        x = self.feature(inputs)\n        x = self.pool1(x)\n        x = self.fc(x)\n        return x","metadata":{"id":"RZAEoATz2_TS","execution":{"iopub.status.busy":"2021-08-25T02:18:24.174122Z","iopub.execute_input":"2021-08-25T02:18:24.174411Z","iopub.status.idle":"2021-08-25T02:18:24.192691Z","shell.execute_reply.started":"2021-08-25T02:18:24.174384Z","shell.execute_reply":"2021-08-25T02:18:24.191793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model(image_size, num_classes, stage_out_channel):\n    inputs = keras.Input((image_size, image_size, 3))\n    outputs = reactnet(num_classes, stage_out_channel)(inputs)\n    model = keras.Model(inputs, outputs)\n    return model","metadata":{"id":"ecVTEGrvq8HT","execution":{"iopub.status.busy":"2021-08-25T02:18:24.194047Z","iopub.execute_input":"2021-08-25T02:18:24.19445Z","iopub.status.idle":"2021-08-25T02:18:24.202876Z","shell.execute_reply.started":"2021-08-25T02:18:24.194409Z","shell.execute_reply":"2021-08-25T02:18:24.201938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"react = model(224, 1000, STAGE_OUT_CHANNEL)\nreact.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T02:18:24.204326Z","iopub.execute_input":"2021-08-25T02:18:24.204811Z","iopub.status.idle":"2021-08-25T02:18:27.722413Z","shell.execute_reply.started":"2021-08-25T02:18:24.20477Z","shell.execute_reply":"2021-08-25T02:18:27.721266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for layer in react.layers[-1].feature.layers:\n#     if 'basic_block' in layer.name:\n#         for i in range(len(layer.trainable_weights)):\n#             print(layer.trainable_weights[i].name)\n#             print(layer.trainable_weights[i].shape)\n#         print('------')\n#         print(len(layer.trainable_weights))\n#         break","metadata":{"id":"AF7afhejvFV7","outputId":"dc3d56fd-a694-4c61-8dea-f5443ba0d61f","execution":{"iopub.status.busy":"2021-08-25T02:18:27.723865Z","iopub.execute_input":"2021-08-25T02:18:27.724174Z","iopub.status.idle":"2021-08-25T02:18:27.728023Z","shell.execute_reply.started":"2021-08-25T02:18:27.724143Z","shell.execute_reply":"2021-08-25T02:18:27.727022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{"id":"gWb2o4YIBoCQ"}},{"cell_type":"code","source":"with strategy.scope():\n    class myLoss(keras.losses.Loss):\n        def __init__(self):\n            super(myLoss, self).__init__(reduction=tf.keras.losses.Reduction.NONE)\n\n        def call(self, y_true, y_pred):\n            model_output_log_prob = tf.math.log(keras.activations.softmax(y_pred))\n#             real_output_soft = keras.activations.softmax(y_true)\n            real_output_soft = y_true\n\n            real_output_soft = tf.expand_dims(real_output_soft, axis=1)\n            model_output_log_prob = tf.expand_dims(model_output_log_prob, axis=-1)\n            cross_entropy_loss = -tf.einsum('bij, bji->bi', real_output_soft, model_output_log_prob)\n\n            return cross_entropy_loss","metadata":{"id":"oGgXh-G7Bqzh","execution":{"iopub.status.busy":"2021-08-25T02:18:27.729537Z","iopub.execute_input":"2021-08-25T02:18:27.729922Z","iopub.status.idle":"2021-08-25T02:18:27.741824Z","shell.execute_reply.started":"2021-08-25T02:18:27.729882Z","shell.execute_reply":"2021-08-25T02:18:27.74083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"test loss 请注意tf中resnet50的输出是已经经过softmax的\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.nn.modules import loss\nclass DistributionLoss(loss._Loss):\n    def forward(self, model_output, real_output):\n\n        self.size_average = True\n        if real_output.requires_grad:\n            raise ValueError(\"real network output should not require gradients.\")\n\n        model_output_log_prob = F.log_softmax(model_output, dim=1)\n        real_output_soft = F.softmax(real_output, dim=1)\n        del model_output, real_output\n\n        real_output_soft = real_output_soft.unsqueeze(1)\n        model_output_log_prob = model_output_log_prob.unsqueeze(2)\n\n        cross_entropy_loss = -torch.bmm(real_output_soft, model_output_log_prob)\n        if self.size_average:\n             cross_entropy_loss = cross_entropy_loss.mean()\n        else:\n             cross_entropy_loss = cross_entropy_loss.sum()\n        return cross_entropy_loss\n    \n    \npred = np.random.normal(size=(2, 1000))\nlabel = np.random.normal(size=(2, 1000))\n\npt_pred = torch.from_numpy(pred)\npt_label = torch.from_numpy(label)\npt_loss_fn = DistributionLoss()\npt_loss = pt_loss_fn(pt_pred, pt_label)\n\nprint(pt_loss)\nprint('------------')\n\n\ntf_pred =tf.convert_to_tensor(pred)\ntf_label =  keras.activations.softmax(tf.convert_to_tensor(label))\ntf_loss_fn = myLoss()\ntf_loss = tf_loss_fn(tf_label, tf_pred)\n# print(tf_loss)\nprint(tf.reduce_mean(tf_loss))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T02:18:27.743002Z","iopub.execute_input":"2021-08-25T02:18:27.743368Z","iopub.status.idle":"2021-08-25T02:18:29.028096Z","shell.execute_reply.started":"2021-08-25T02:18:27.743324Z","shell.execute_reply":"2021-08-25T02:18:29.027196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Learning rate schedule","metadata":{}},{"cell_type":"code","source":"class MyLRSchedule(keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, initial_learning_rate, epochs, step_epoch):\n        self.initial_learning_rate = initial_learning_rate\n        self.all_step = epochs * step_epoch\n        \n    def __call__(self, step):\n        return self.initial_learning_rate*(1.0 - (step/(self.all_step)))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T02:18:29.029122Z","iopub.execute_input":"2021-08-25T02:18:29.029389Z","iopub.status.idle":"2021-08-25T02:18:29.034981Z","shell.execute_reply.started":"2021-08-25T02:18:29.029363Z","shell.execute_reply":"2021-08-25T02:18:29.034027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"8aqEEx5mqVDe"}},{"cell_type":"code","source":"def read_tfrecord(example):\n    features = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'class': tf.io.FixedLenFeature([], tf.int64),\n        'filename': tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, features)\n    image = tf.image.decode_jpeg(example['image'])\n    class_num = example['class']\n    filename = example['filename']\n    return image, class_num, filename","metadata":{"id":"48XxwpPoKE5K","execution":{"iopub.status.busy":"2021-08-25T02:18:29.036369Z","iopub.execute_input":"2021-08-25T02:18:29.036752Z","iopub.status.idle":"2021-08-25T02:18:29.046111Z","shell.execute_reply.started":"2021-08-25T02:18:29.036712Z","shell.execute_reply":"2021-08-25T02:18:29.045133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_hw(image):\n    shape = tf.shape(image)\n    return shape[0], shape[1]\n\ndef resize_and_crop_image(image, target_size):\n    h, w = image_hw(image)\n    th, tw = target_size\n    image = tf.cond(\n        (w*th)/(h*tw) <1,\n        lambda: tf.image.resize(image, [h * tw/w, w* tw/w]),\n        lambda: tf.image.resize(image, [h * th/h, w*th/h])\n    )\n    nh, nw = image_hw(image)\n    image = tf.image.crop_to_bounding_box(image, (nh-th)//2, (nw-tw)//2, th, tw)\n    image = tf.reshape(image, [*target_size, 3])\n    return image\n\ndef normalize(image, dtype):\n    image = tf.cast(image, dtype) / 255.0\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-08-25T02:18:29.047271Z","iopub.execute_input":"2021-08-25T02:18:29.047588Z","iopub.status.idle":"2021-08-25T02:18:29.061172Z","shell.execute_reply.started":"2021-08-25T02:18:29.04756Z","shell.execute_reply":"2021-08-25T02:18:29.060179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset(tfrec_roots, image_size, is_train, dtype=tf.float32, batch_size=None, cache=False, drop_filename=True):\n    AUTO = tf.data.experimental.AUTOTUNE\n    pattern = '/train-*.tfrec' if is_train else '/val.tfrec'\n    tfrec_paths = []\n    for tfrec_root in tfrec_roots:\n        tfrec_paths.extend(tf.io.gfile.glob(tfrec_root.rstrip('/')+pattern))\n#     print('tfrec paths', tfrec_paths)\n    dataset = tf.data.TFRecordDataset(tfrec_paths, num_parallel_reads=AUTO)\n    options_no_order = tf.data.Options()\n    options_no_order.experimental_deterministic = False\n    dataset = dataset.with_options(options_no_order)\n\n    def process(filename):\n        image, label, filename = read_tfrecord(filename)\n        image = resize_and_crop_image(image, target_size=image_size)\n        image = tf.image.random_flip_left_right(image)\n        image = normalize(image, dtype=dtype)\n        result = (image, label)\n        if not drop_filename:\n            result += (filenmae,)\n        return result\n        \n    dataset = dataset.map(process, num_parallel_calls=AUTO)\n    if cache:\n        dataset = dataset.cache()\n    if is_train:\n        dataset = dataset.shuffle(4096)\n    if batch_size is not None:\n        dataset = dataset.batch(batch_size)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(AUTO)\n    return dataset","metadata":{"id":"ROFfrOieLgBd","execution":{"iopub.status.busy":"2021-08-25T02:18:29.062439Z","iopub.execute_input":"2021-08-25T02:18:29.062788Z","iopub.status.idle":"2021-08-25T02:18:29.074012Z","shell.execute_reply.started":"2021-08-25T02:18:29.062756Z","shell.execute_reply":"2021-08-25T02:18:29.072538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train","metadata":{"id":"JxwAVgY36gGo"}},{"cell_type":"code","source":"from pathlib import Path\nfrom kaggle_datasets import KaggleDatasets\ngcs_path = [KaggleDatasets().get_gcs_path(p.name) for p in Path('/kaggle/input/').iterdir()]\nIMAGE_SIZE = 224\nN_CLASSES = 1000\nXLA = 0\nMIXED = 1\nBATCH_SIZE = 256\nEPOCHS = 256\nLEARNING_RATE = 1.25e-3\nMOMENTUM = 0.9\nLABEL_SMOOTH =0.1\nTEACHER = 'ResNet50'","metadata":{"id":"2z-nkm6zm-5A","execution":{"iopub.status.busy":"2021-08-25T02:18:29.074999Z","iopub.execute_input":"2021-08-25T02:18:29.075257Z","iopub.status.idle":"2021-08-25T02:18:30.229341Z","shell.execute_reply.started":"2021-08-25T02:18:29.075233Z","shell.execute_reply":"2021-08-25T02:18:30.228435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if MIXED:\n    dtype = tf.bfloat16 if tpu else tf.float16\nNUM_TRAIN_IMAGES = 1281167\nNUM_VAL_IMAGES = 50000\nSTEP_PER_EPOCH = NUM_TRAIN_IMAGES // BATCH_SIZE\nVAL_PER_EPOCH = NUM_VAL_IMAGES // BATCH_SIZE\nPER_REPICE_BATCH_SIZE = BATCH_SIZE // strategy.num_replicas_in_sync\nSAVE_PATH = './model.h5'\n\ntrain_dataset = strategy.experimental_distribute_datasets_from_function(\n    lambda _:dataset(\n            gcs_path,\n            is_train=True, \n            image_size=(IMAGE_SIZE, IMAGE_SIZE), \n            cache=False, \n            batch_size=PER_REPICE_BATCH_SIZE,\n            drop_filename=True,\n            dtype=dtype,\n            ))\nval_dataset = strategy.experimental_distribute_datasets_from_function(lambda _:dataset(\n            gcs_path,\n            is_train=False, \n            image_size=(IMAGE_SIZE, IMAGE_SIZE), \n            cache=True, \n            batch_size=PER_REPICE_BATCH_SIZE,\n            drop_filename=True,\n            dtype=dtype,\n            ))\ntrain_iterator = iter(train_dataset)\nval_iterator = iter(val_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T02:18:30.233783Z","iopub.execute_input":"2021-08-25T02:18:30.234095Z","iopub.status.idle":"2021-08-25T02:18:32.032015Z","shell.execute_reply.started":"2021-08-25T02:18:30.234064Z","shell.execute_reply":"2021-08-25T02:18:32.031093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"load model\"\"\"\nwith strategy.scope():\n    model_teacher = keras.applications.__dict__[TEACHER](weights='imagenet', include_top=True)\n    model_teacher.trainable = False\n\n    model_student = model(224, 1000, STAGE_OUT_CHANNEL)\n\n    lr_schedule = MyLRSchedule(LEARNING_RATE, EPOCHS, STEP_PER_EPOCH)\n    optimizer = keras.optimizers.Adam(\n        learning_rate=lr_schedule,\n        beta_1=0.9,\n        beta_2=0.999,\n#         weight_decay=5e-6,\n    )\n    criterion = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    criterion_smooth = keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0)\n    criterion_kd = myLoss()\n    training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('training_accuracy', dtype=tf.float32)\n    training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n    val_accuracy =tf.keras.metrics.SparseCategoricalAccuracy('val_accuracy', dtype=tf.float32)\n\n\n@tf.function\ndef train_step(iterator):\n    def train_fn(inputs):\n        x, y = inputs\n        with tf.GradientTape() as tape:\n            logits_student = model_student(x, training=True)\n            logits_teacher = model_teacher(x, training=False)\n            loss = criterion_kd(logits_teacher, logits_student)\n            loss = tf.nn.compute_average_loss(loss, global_batch_size=BATCH_SIZE)\n            \n        grads = tape.gradient(loss, model_student.trainable_weights)\n        optimizer.apply_gradients(list(zip(grads, model_student.trainable_weights)))\n        training_accuracy.update_state(y, logits_student)\n        training_loss.update_state(loss)\n    \n    strategy.run(train_fn, args=(next(iterator),))\n    \n@tf.function\ndef test_step(iterator):\n    def test_fn(inputs):\n        x, y = inputs\n        val_logits = model_teacher(x, training=False)\n        val_accuracy.update_state(y, val_logits)\n    strategy.run(test_fn, args=(next(iterator),))","metadata":{"id":"_WBi0QOF3s8y","outputId":"c43a8c11-6b31-4e7a-f064-f33c51d017b5","execution":{"iopub.status.busy":"2021-08-25T02:18:32.033505Z","iopub.execute_input":"2021-08-25T02:18:32.033948Z","iopub.status.idle":"2021-08-25T02:18:50.942293Z","shell.execute_reply.started":"2021-08-25T02:18:32.033908Z","shell.execute_reply":"2021-08-25T02:18:50.941292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    print('\\nstart of epoch %d'%(epoch,))\n#     for step in range(STEP_PER_EPOCH):\n#         train_step(train_iterator)\n#         if step%400 == 0:\n#             train_acc = training_accuracy.result()\n#             print('training acc over epoch: %.4f, %4f'%(float(train_acc), float(training_loss.result())))\n            \n#     train_acc = training_accuracy.result()\n#     print('............training acc over epoch: %.4f, %4f'%(float(train_acc), float(training_loss.result())))\n#     training_accuracy.reset_states()\n#     training_loss.reset_states()\n\n    for step in range(VAL_PER_EPOCH):\n        test_step(val_iterator)\n    val_acc = val_accuracy.result()\n    print('validation acc over epoch: %.4f'%(float(val_acc),))\n    val_accuracy.reset_states()\n    break","metadata":{"execution":{"iopub.status.busy":"2021-08-25T02:18:50.943592Z","iopub.execute_input":"2021-08-25T02:18:50.943892Z","iopub.status.idle":"2021-08-25T02:19:15.654521Z","shell.execute_reply.started":"2021-08-25T02:18:50.943862Z","shell.execute_reply":"2021-08-25T02:19:15.653474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}